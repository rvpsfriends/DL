{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4607952,"sourceType":"datasetVersion","datasetId":2604803},{"sourceId":8208729,"sourceType":"datasetVersion","datasetId":4499580}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"a. BASIC OBJECT CLASSIFICATION USING PRE-TRAINED VGG16 MODEL","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.models import Model\nfrom keras.layers import Dense, Flatten\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\n\n# Load the dataset\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n\n# Load the VGG16 model without the top fully connected layers\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n\n# Add custom layers on top of the base model\nx = Flatten()(base_model.output)\nx = Dense(256, activation='relu')(x)\npredictions = Dense(10, activation='softmax')(x)\n\n# Define the complete model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze the base model layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Preprocess the data\nx_train = preprocess_input(x_train)\nx_test = preprocess_input(x_test)\n\n# Create data generators for data augmentation\ndatagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\ndatagen.fit(x_train)\n\n# Train the model\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nmodel.fit(datagen.flow(x_train, y_train, batch_size=32), validation_data=(x_test, y_test), epochs=5, callbacks=[early_stopping])\n\n# Evaluate the model on test data\ntest_loss, test_accuracy = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T14:42:05.458502Z","iopub.execute_input":"2024-09-25T14:42:05.459637Z","iopub.status.idle":"2024-09-25T14:46:15.205860Z","shell.execute_reply.started":"2024-09-25T14:42:05.459590Z","shell.execute_reply":"2024-09-25T14:46:15.204714Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1727275335.010731      96 service.cc:145] XLA service 0x7cec7400f940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1727275335.010793      96 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   8/1563\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 25ms/step - accuracy: 0.1017 - loss: 17.1536","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1727275337.483601      96 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 32ms/step - accuracy: 0.4693 - loss: 3.2503 - val_accuracy: 0.6165 - val_loss: 1.1318\nEpoch 2/5\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - accuracy: 0.6059 - loss: 1.1279 - val_accuracy: 0.6382 - val_loss: 1.0715\nEpoch 3/5\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 30ms/step - accuracy: 0.6312 - loss: 1.0581 - val_accuracy: 0.6471 - val_loss: 1.0485\nEpoch 4/5\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 30ms/step - accuracy: 0.6448 - loss: 1.0245 - val_accuracy: 0.6488 - val_loss: 1.0721\nEpoch 5/5\n\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 30ms/step - accuracy: 0.6482 - loss: 1.0028 - val_accuracy: 0.6508 - val_loss: 1.0374\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6525 - loss: 1.0309\nTest Accuracy: 65.08%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# b. IMAGENET CLASSIFICATION WITH DEEP RESIDUAL NETWORKS (RESNET)","metadata":{}},{"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nimport numpy as np\n\n# Load the pre-trained ResNet50 model\nmodel = ResNet50(weights='imagenet')\n\n# Load an image file that contains an image to be classified\nimg_path = '/kaggle/input/catcat/train/dogs/dog_10.jpg'  # Replace with the path to your image\nimg = image.load_img(img_path, target_size=(224, 224))\n\n# Convert the image to a numpy array\nx = image.img_to_array(img)\n\n# Add a batch dimension (since the model expects a batch of images)\nx = np.expand_dims(x, axis=0)\n\n# Preprocess the input image for the model\nx = preprocess_input(x)\n\n# Predict the class of the image\npredictions = model.predict(x)\n\n# Decode the top 3 predictions into human-readable class names\nprint('Predicted:', decode_predictions(predictions, top=3)[0])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T14:48:01.790721Z","iopub.execute_input":"2024-09-25T14:48:01.791890Z","iopub.status.idle":"2024-09-25T14:48:07.687430Z","shell.execute_reply.started":"2024-09-25T14:48:01.791800Z","shell.execute_reply":"2024-09-25T14:48:07.686329Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\nDownloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nPredicted: [('n02105162', 'malinois', 0.804456), ('n03803284', 'muzzle', 0.050654963), ('n02106662', 'German_shepherd', 0.035840467)]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# C. CLASSIFYING SPECIES OF FLOWERS USING TRANSFER LEARNING","metadata":{}},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.layers import Dense, Flatten\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping\n\n# Set up data directories\ntrain_dir = '/kaggle/input/flower-classification-5-classes-roselilyetc/Flower Classification/Flower Classification/Testing Data'\nvalid_dir = '/kaggle/input/flower-classification-5-classes-roselilyetc/Flower Classification/Flower Classification/Training Data'\n\n# Create data generators\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nvalid_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size=(224, 224),\n                                                    batch_size=32, class_mode='categorical')\nvalid_generator = valid_datagen.flow_from_directory(valid_dir, target_size=(224, 224),\n                                                    batch_size=32, class_mode='categorical')\n\n# Load the pre-trained VGG16 model without the top fully connected layers\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Add custom layers on top of the base model\nx = base_model.output\nx = Flatten()(x)\nx = Dense(256, activation='relu')(x)\npredictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n\n# Define the complete model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze the base model layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Set up early stopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Train the model\nmodel.fit(train_generator, epochs=5, validation_data=valid_generator, callbacks=[early_stopping])\n\n# Evaluate the model on validation data\nloss, accuracy = model.evaluate(valid_generator)\nprint(f'Validation Accuracy: {accuracy * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T14:53:12.127244Z","iopub.execute_input":"2024-09-25T14:53:12.128358Z","iopub.status.idle":"2024-09-25T14:55:11.424715Z","shell.execute_reply.started":"2024-09-25T14:53:12.128308Z","shell.execute_reply":"2024-09-25T14:55:11.423540Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 958 images belonging to 5 classes.\nFound 5000 images belonging to 5 classes.\nEpoch 1/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1s/step - accuracy: 0.4145 - loss: 3.3267 - val_accuracy: 0.6896 - val_loss: 0.8898\nEpoch 2/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 480ms/step - accuracy: 0.8097 - loss: 0.5312 - val_accuracy: 0.7250 - val_loss: 0.8053\nEpoch 3/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 477ms/step - accuracy: 0.9604 - loss: 0.1881 - val_accuracy: 0.7444 - val_loss: 0.7877\nEpoch 4/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 459ms/step - accuracy: 0.9878 - loss: 0.1073 - val_accuracy: 0.7310 - val_loss: 0.8181\nEpoch 5/5\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 469ms/step - accuracy: 1.0000 - loss: 0.0458 - val_accuracy: 0.7536 - val_loss: 0.7745\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.7415 - loss: 0.8198\nValidation Accuracy: 75.36%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}